{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motor Control\n",
    "We'll start with simulated [PI](https://en.wikipedia.org/wiki/PID_controller) control of a DC Motor, and view a step response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pwm_control(w_desired,w_measured,Kp,Ki,e_sum):\n",
    "    \n",
    "#     duty_cycle = min(max(0,Kp*(w_desired-w_measured) + Ki*e_sum),1)\n",
    "#     e_sum = e_sum + w_desired-w_measured\n",
    "    \n",
    "#     return duty_cycle, e_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def motor_simulator(w,duty_cycle):\n",
    "\n",
    "#     I = 5\n",
    "#     dt = 0.1\n",
    "#     d = 1\n",
    "    \n",
    "#     torque = I*duty_cycle\n",
    "\n",
    "#     if (w > 0):\n",
    "#         w = min(w + dt*(torque - d*w),3)\n",
    "#     elif (w < 0):\n",
    "#         w = max(w + dt*(torque - d*w),-3)\n",
    "#     else:\n",
    "#         w = w + dt*(torque)\n",
    "\n",
    "#     return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try playing with the controller gains to see how this affects the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = 0\n",
    "# w_desired = 2.0\n",
    "# w_measured = 0.0\n",
    "# duty_cycle = 0\n",
    "\n",
    "# plt.figure(figsize=(15,5))\n",
    "# e_sum = 0\n",
    "\n",
    "# for j in range(50):\n",
    "    \n",
    "    \n",
    "#     duty_cycle,e_sum = pwm_control(w_desired,w_measured,Kp=1.0,Ki=0.25,e_sum=e_sum)\n",
    "    \n",
    "#     w_measured = motor_simulator(w_measured,duty_cycle)\n",
    "    \n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.plot(j,w_measured,'bo')\n",
    "#     plt.plot(j,w_desired,'r+')\n",
    "    \n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.plot(j,duty_cycle,'bo')\n",
    "    \n",
    "#     display.clear_output(wait=True)\n",
    "#     display.display(plt.gcf())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential drive robot model\n",
    "Now we'll put two motors together, and simulate a differential drive robot. We'll use some of the motion models and derivations in [this paper](https://doi.org/10.1109/ICRA.2012.6224684). This motion model can be used to estimate the position of our robot given the commands we send to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffDriveRobot:\n",
    "    \n",
    "    def __init__(self,inertia=5, dt=0.1, drag=0.2, wheel_radius=0.05, wheel_sep=0.15):\n",
    "        \n",
    "        self.x = 0.0 # y-position\n",
    "        self.y = 0.0 # y-position \n",
    "        self.th = 0.0 # orientation\n",
    "        \n",
    "        self.wl = 0.0 #rotational velocity left wheel\n",
    "        self.wr = 0.0 #rotational velocity right wheel\n",
    "        \n",
    "        self.I = inertia\n",
    "        self.d = drag\n",
    "        self.dt = dt\n",
    "        \n",
    "        self.r = wheel_radius\n",
    "        self.l = wheel_sep\n",
    "    \n",
    "    # Should be replaced by motor encoder measurement which measures how fast wheel is turning\n",
    "    # Here, we simulate the real system and measurement\n",
    "    def motor_simulator(self,w,duty_cycle):\n",
    "        \n",
    "        torque = self.I*duty_cycle\n",
    "        \n",
    "        if (w > 0):\n",
    "            w = min(w + self.dt*(torque - self.d*w),3)\n",
    "        elif (w < 0):\n",
    "            w = max(w + self.dt*(torque - self.d*w),-3)\n",
    "        else:\n",
    "            w = w + self.dt*(torque)\n",
    "        \n",
    "        return w\n",
    "    \n",
    "    # Veclocity motion model\n",
    "    def base_velocity(self,wl,wr):\n",
    "        \n",
    "        v = (wl*self.r + wr*self.r)/2.0\n",
    "        \n",
    "        w = (wl - wr)/self.l\n",
    "        \n",
    "        return v, w\n",
    "    \n",
    "    # Kinematic motion model\n",
    "    def pose_update(self,duty_cycle_l,duty_cycle_r):\n",
    "        \n",
    "        self.wl = self.motor_simulator(self.wl,duty_cycle_l)\n",
    "        self.wr = self.motor_simulator(self.wr,duty_cycle_r)\n",
    "        \n",
    "        v, w = self.base_velocity(self.wl,self.wr)\n",
    "        \n",
    "        self.x = self.x + self.dt*v*np.cos(self.th)\n",
    "        self.y = self.y + self.dt*v*np.sin(self.th)\n",
    "        self.th = self.th + w*self.dt\n",
    "        \n",
    "        return self.x, self.y, self.th\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kinematic motion control\n",
    "Let's use the PI motor controller to control the forward and rotational velocity of our robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotController:\n",
    "    \n",
    "    def __init__(self,Kp=0.1,Ki=0.01,wheel_radius=0.02, wheel_sep=0.1):\n",
    "        \n",
    "        self.Kp = Kp\n",
    "        self.Ki = Ki\n",
    "        self.r = wheel_radius\n",
    "        self.l = wheel_sep\n",
    "        self.e_sum_l = 0\n",
    "        self.e_sum_r = 0\n",
    "        \n",
    "    def p_control(self,w_desired,w_measured,e_sum):\n",
    "        \n",
    "        duty_cycle = min(max(-1,self.Kp*(w_desired-w_measured) + self.Ki*e_sum),1)\n",
    "        \n",
    "        e_sum = e_sum + (w_desired-w_measured)\n",
    "        \n",
    "        return duty_cycle, e_sum\n",
    "        \n",
    "        \n",
    "    def drive(self,v_desired,w_desired,wl,wr):\n",
    "        \n",
    "        wl_desired = v_desired/self.r + self.l*w_desired/2 \n",
    "        wr_desired = v_desired/self.r - self.l*w_desired/2\n",
    "        \n",
    "        duty_cycle_l,self.e_sum_l = self.p_control(wl_desired,wl,self.e_sum_l)\n",
    "        duty_cycle_r,self.e_sum_r = self.p_control(wr_desired,wr,self.e_sum_r)\n",
    "        \n",
    "        return duty_cycle_l, duty_cycle_r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = DiffDriveRobot(inertia=5, dt=0.1, drag=1, wheel_radius=0.05, wheel_sep=0.15)\n",
    "controller = RobotController(Kp=1,Ki=0.25,wheel_radius=0.05,wheel_sep=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "poses = []\n",
    "velocities = []\n",
    "duty_cycle_commands = []\n",
    "for i in range(130):\n",
    "\n",
    "    # Example motion using controller \n",
    "    if i < 20: # drive in circular path (turn left) for 10 s\n",
    "        duty_cycle_l,duty_cycle_r = controller.drive(0.1,0.01,robot.wl,robot.wr)\n",
    "    elif i > 20 and i < 50: \n",
    "         duty_cycle_l,duty_cycle_r = controller.drive(0.1,0.4,robot.wl,robot.wr)\n",
    "    elif i > 50 or i < 120: # drive in circular path (turn right) for 10 s\n",
    "        duty_cycle_l,duty_cycle_r = controller.drive(1,1,robot.wl,robot.wr)\n",
    "    else:\n",
    "        duty_cycle_l,duty_cycle_r = (0,0)\n",
    "    # Simulate robot motion - send duty cycle command to robot\n",
    "    x,y,th = robot.pose_update(duty_cycle_l,duty_cycle_r)\n",
    "    \n",
    "    # Log data\n",
    "    poses.append([x,y,th])\n",
    "    duty_cycle_commands.append([duty_cycle_l,duty_cycle_r])\n",
    "    velocities.append([robot.wl,robot.wr])\n",
    "    \n",
    "    # Plot robot data\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(np.array(poses)[:,0],np.array(poses)[:,1])\n",
    "    plt.plot(x,y,'k',marker='+')\n",
    "    plt.quiver(x,y,0.1*np.cos(th),0.1*np.sin(th))\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    plt.xlabel('x-position (m)')\n",
    "    plt.ylabel('y-position (m)')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(np.arange(i+1)*robot.dt,np.array(duty_cycle_commands))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Duty cycle')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(np.arange(i+1)*robot.dt,np.array(velocities))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Wheel $\\omega$')\n",
    "    plt.legend(['Left wheel', 'Right wheel'])\n",
    "    plt.grid()\n",
    "    \n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driving with tentacles\n",
    "Ok, now let's put together an algorithm to control our robot to move towards goals. We'll use a simplified version of a strategy called [dynamic window rollout](https://doi.org/10.1109/ROBOT.2007.363613), or [driving with tentacles](https://doi.org/10.1002/rob.20256). This is a type of model predictive control, which is commonly used in chemical and industrial manufacturing plants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TentaclePlanner:\n",
    "    \n",
    "    def __init__(self,dt=0.1,steps=5,alpha=1,beta=0.1):\n",
    "        \n",
    "        self.dt = dt\n",
    "        self.steps = steps\n",
    "        # Tentacles are possible trajectories to follow\n",
    "        self.tentacles = [(0.0,0.5),(0.0,-0.5),(0.1,1.0),(0.1,-1.0),(0.1,0.5),(0.1,-0.5),(0.1,0.0),(0.0,0.0)]\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "    \n",
    "    # Play a trajectory and evaluate where you'd end up\n",
    "    def roll_out(self,v,w,goal_x,goal_y,goal_th,x,y,th):\n",
    "        \n",
    "        for j in range(self.steps):\n",
    "        \n",
    "            x = x + self.dt*v*np.cos(th)\n",
    "            y = y + self.dt*v*np.sin(th)\n",
    "            th = (th + w*self.dt)\n",
    "        \n",
    "        e_th = goal_th-th\n",
    "        e_th = np.arctan2(np.sin(e_th),np.cos(e_th))\n",
    "        \n",
    "        return self.alpha*((goal_x-x)**2 + (goal_y-y)**2) + self.beta*(e_th**2)\n",
    "    \n",
    "    # Choose trajectory that will get you closest to the goal\n",
    "    def plan(self,goal_x,goal_y,goal_th,x,y,th):\n",
    "        \n",
    "        costs =[]\n",
    "        for v,w in self.tentacles:\n",
    "            costs.append(self.roll_out(v,w,goal_x,goal_y,goal_th,x,y,th))\n",
    "        \n",
    "        best_idx = np.argmin(costs)\n",
    "        \n",
    "        return self.tentacles[best_idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = DiffDriveRobot(inertia=10, dt=0.1, drag=2, wheel_radius=0.05, wheel_sep=0.15)\n",
    "controller = RobotController(Kp=1.0,Ki=0.15,wheel_radius=0.05,wheel_sep=0.15)\n",
    "planner = TentaclePlanner(dt=0.1,steps=2,alpha=1,beta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (384591884.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_116/384591884.py\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    print('x:',x)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "poses = []\n",
    "velocities = []\n",
    "duty_cycle_commands = []\n",
    "\n",
    "goal_x = 2*np.random.rand()-1\n",
    "goal_y = 2*np.random.rand()-1\n",
    "goal_th = 0\n",
    "\n",
    "print(goal_x)\n",
    "print(goal_y)\n",
    "print(goal_th)\n",
    "\n",
    "for i in range(200):\n",
    "\n",
    "    # Plan using tentacles\n",
    "    v,w = planner.plan(goal_x,goal_y,goal_th,robot.x,robot.y,robot.th)\n",
    "    \n",
    "    duty_cycle_l,duty_cycle_r = controller.drive(v,w,robot.wl,robot.wr)\n",
    "    \n",
    "    # Simulate robot motion - send duty cycle command to robot\n",
    "    x,y,th = robot.pose_update(duty_cycle_l,duty_cycle_r)\n",
    "    \n",
    "    # Log data\n",
    "    poses.append([x,y,th])\n",
    "    duty_cycle_commands.append([duty_cycle_l,duty_cycle_r])\n",
    "    velocities.append([robot.wl,robot.wr])\n",
    "    \n",
    "    \n",
    "    print('v: ',v)\n",
    "    print('w: ',w)\n",
    "    print('x:',x)\n",
    "    print('y:',y)\n",
    "    print('th:',th)\n",
    "    print('\\n')\n",
    "    \n",
    "    # Plot robot data\n",
    "    plt.clf()\n",
    "    plt.subplot(1,2,1)\n",
    "#     plt.plot(np.array(poses)[:,0],np.array(poses)[:,1])\n",
    "#     plt.plot(x,y,'k',marker='+')\n",
    "#     plt.quiver(x,y,0.1*np.cos(th),0.1*np.sin(th))\n",
    "    plt.plot(goal_x,goal_y,'x',markersize=5)\n",
    "    plt.quiver(goal_x,goal_y,0.1*np.cos(goal_th),0.1*np.sin(goal_th))\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    plt.xlabel('x-position (m)')\n",
    "    plt.ylabel('y-position (m)')\n",
    "    plt.grid()\n",
    "    \n",
    "#     plt.subplot(2,2,2)\n",
    "#     plt.plot(np.arange(i+1)*robot.dt,np.array(duty_cycle_commands))\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Duty cycle')\n",
    "#     plt.grid()\n",
    "    \n",
    "#     plt.subplot(2,2,4)\n",
    "#     plt.plot(np.arange(i+1)*robot.dt,np.array(velocities))\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Wheel $\\omega$')\n",
    "#     plt.legend(['Left wheel', 'Right wheel'])\n",
    "#     plt.grid()\n",
    "    \n",
    "    \n",
    "#     display.clear_output(wait=True)\n",
    "#     display.display(plt.gcf())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obstacle avoidance \n",
    "\n",
    "Now, let's modify our tentacle planner to avoid obstacles (assuming we know where they are). You can use a similar strategy with the ultrasound detector. If an object is detected on the left, ignore tentacles turning left when computing the cost. If an object is detected on the right, ignore tentacles turning right when computing the cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TentaclePlanner:\n",
    "    \n",
    "#     def __init__(self,obstacles,dt=0.1,steps=5,alpha=1,beta=0.1):\n",
    "        \n",
    "#         self.dt = dt\n",
    "#         self.steps = steps\n",
    "#         # Tentacles are possible trajectories to follow\n",
    "#         self.tentacles = [(0.0,1.0),(0.0,-1.0),(0.1,1.0),(0.1,-1.0),(0.1,0.5),(0.1,-0.5),(0.1,0.0),(0.0,0.0)]\n",
    "        \n",
    "#         self.alpha = alpha\n",
    "#         self.beta = beta\n",
    "        \n",
    "#         self.obstacles = obstacles\n",
    "    \n",
    "#     # Play a trajectory and evaluate where you'd end up\n",
    "#     def roll_out(self,v,w,goal_x,goal_y,goal_th,x,y,th):\n",
    "        \n",
    "#         for j in range(self.steps):\n",
    "        \n",
    "#             x = x + self.dt*v*np.cos(th)\n",
    "#             y = y + self.dt*v*np.sin(th)\n",
    "#             th = (th + w*self.dt)\n",
    "            \n",
    "#             if (self.check_collision(x,y)):\n",
    "#                 return np.inf\n",
    "        \n",
    "#         # Wrap angle error -pi,pi\n",
    "#         e_th = goal_th-th\n",
    "#         e_th = np.arctan2(np.sin(e_th),np.cos(e_th))\n",
    "        \n",
    "#         cost = self.alpha*((goal_x-x)**2 + (goal_y-y)**2) + self.beta*(e_th**2)\n",
    "        \n",
    "#         return cost\n",
    "    \n",
    "#     def check_collision(self,x,y):\n",
    "        \n",
    "#         min_dist = np.min(np.sqrt((x-self.obstacles[:,0])**2+(y-self.obstacles[:,1])**2))\n",
    "        \n",
    "#         if (min_dist < 0.1):\n",
    "#             return True\n",
    "#         return False\n",
    "        \n",
    "    \n",
    "#     # Choose trajectory that will get you closest to the goal\n",
    "#     def plan(self,goal_x,goal_y,goal_th,x,y,th):\n",
    "        \n",
    "#         costs =[]\n",
    "#         for v,w in self.tentacles:\n",
    "#             costs.append(self.roll_out(v,w,goal_x,goal_y,goal_th,x,y,th))\n",
    "        \n",
    "#         best_idx = np.argmin(costs)\n",
    "        \n",
    "#         return self.tentacles[best_idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obstacles = 2*np.random.rand(20,2)-1\n",
    "# robot = DiffDriveRobot(inertia=10, dt=0.1, drag=2, wheel_radius=0.05, wheel_sep=0.15)\n",
    "# controller = RobotController(Kp=1.0,Ki=0.15,wheel_radius=0.05,wheel_sep=0.15)\n",
    "# planner = TentaclePlanner(obstacles,dt=0.1,steps=10,alpha=1,beta=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,9))\n",
    "\n",
    "# poses = []\n",
    "# velocities = []\n",
    "# duty_cycle_commands = []\n",
    "\n",
    "# goal_x = 2*np.random.rand()-1\n",
    "# goal_y = 2*np.random.rand()-1\n",
    "# goal_th = 2*np.pi*np.random.rand()-np.pi\n",
    "\n",
    "# for i in range(200):\n",
    "\n",
    "#     # Example motion using controller \n",
    "#     v,w = planner.plan(goal_x,goal_y,goal_th,robot.x,robot.y,robot.th)\n",
    "    \n",
    "#     duty_cycle_l,duty_cycle_r = controller.drive(v,w,robot.wl,robot.wr)\n",
    "    \n",
    "#     # Simulate robot motion - send duty cycle command to controller\n",
    "#     x,y,th = robot.pose_update(duty_cycle_l,duty_cycle_r)\n",
    "    \n",
    "#     # Log data\n",
    "#     poses.append([x,y,th])\n",
    "#     duty_cycle_commands.append([duty_cycle_l,duty_cycle_r])\n",
    "#     velocities.append([robot.wl,robot.wr])\n",
    "    \n",
    "#     # Plot robot data\n",
    "#     plt.clf()\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.plot(np.array(poses)[:,0],np.array(poses)[:,1])\n",
    "#     plt.plot(x,y,'k',marker='+')\n",
    "#     plt.quiver(x,y,0.1*np.cos(th),0.1*np.sin(th))\n",
    "#     plt.plot(goal_x,goal_y,'x',markersize=5)\n",
    "#     plt.quiver(goal_x,goal_y,0.1*np.cos(goal_th),0.1*np.sin(goal_th))\n",
    "    \n",
    "#     plt.plot(obstacles[:,0],obstacles[:,1],'ko',markersize=15)\n",
    "#     plt.xlim(-1,1)\n",
    "#     plt.ylim(-1,1)\n",
    "#     plt.xlabel('x-position (m)')\n",
    "#     plt.ylabel('y-position (m)')\n",
    "#     plt.grid()\n",
    "    \n",
    "#     plt.subplot(2,2,2)\n",
    "#     plt.plot(np.arange(i+1)*robot.dt,np.array(duty_cycle_commands))\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Duty cycle')\n",
    "#     plt.grid()\n",
    "    \n",
    "#     plt.subplot(2,2,4)\n",
    "#     plt.plot(np.arange(i+1)*robot.dt,np.array(velocities))\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Wheel $\\omega$')\n",
    "#     plt.legend(['Left wheel', 'Right wheel'])\n",
    "#     plt.grid()\n",
    "    \n",
    "    \n",
    "#     display.clear_output(wait=True)\n",
    "#     display.display(plt.gcf())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, we now have all the pieces to navigate our robot. We just need something to set the goals now (sometimes the controller will fail to reach a goal, and you will need to select an alternative goal). \n",
    "\n",
    "Unfortunately, you'll find that the real world isn't perfect, and your position estimate of the robot will quickly go wrong, no matter how well you try to calibrate it. The wheels will slip, the encoders will mis-count, the model will be wrong and the controller errors will eventually accumulate. We call this odometry drift, and the only way around this is to perform simulataneous localisation and mapping or to update your position using an alternative measurement system. Still, the strategy above should take you pretty far.\n",
    "\n",
    "If you're interested in learning more about mobile robot navigation, read the amazing textbook [Probabilistic Robotics](https://mitpress.mit.edu/books/probabilistic-robotics) by Thrun, Burgard and Fox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6dcbaf4ac2bd99648670c9110b8aca28ffd86286d0f52155fae7e3850336012f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
